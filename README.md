# 🧠 My Voice Assistant — Mind-Driven AI Assistant

My Voice Assistant is a next-generation voice assistant designed to go beyond traditional speech recognition. Inspired by the concept of brain-computer interfaces (BCIs), it aims to create a system that can interpret **human thoughts**, emotions, or subtle intent — not just spoken words.

## 🚀 Vision

> "What if machines could understand us before we even speak?"

The long-term vision is to integrate with advanced neural input systems (like EEG headsets) to create a **mind-controlled assistant** that helps users with day-to-day tasks using natural intent and thought patterns.

---

## ✨ Features

- 🎤 Voice Input & Command Recognition
- 🧠 Thought Detection Module *(experimental)*
- 🧭 Intent Understanding (NLP + Sentiment)
- 🤖 Smart Task Execution (search, notes, reminders, etc.)
- 💬 Text-to-Speech (TTS) Response
- 🧪 Brainwave Data Integration (BCI - optional)

---

## 🧰 Tech Stack

| Technology | Purpose |
|------------|---------|
| Python     | Core logic and scripting |
| SpeechRecognition | Capture voice commands |
| pyttsx3    | Text-to-speech conversion |
| OpenAI GPT | Intent and NLP understanding |
| EEG Device SDK (like NeuroSky / OpenBCI) | *(optional)* Thought input |
| EEL MODULE | Optional: REST API for assistant |
| React Native or Flutter | *(Future)* Mobile interface |

---

## 🛠️ Installation

1. **Clone the repo**
   ```bash
   git clone https://github.com/algorithnicmind /voice_assistant.git
   cd voice_assistant   
pip install -r requirements.txt
python main.py
must on the server.py 

> Assistant: "Hello Boss! What can I do for you today?"
> You: [Think OR Say] "What’s the weather like in Delhi?"
> Assistant: [fetches and speaks result]


hy developers we are hyper coders from DRIEMS polytechnic , we are creating  a project for my final year 
jut dowload the code and commite your changes
Remeber you have to change the config.py means paste your actual API 
